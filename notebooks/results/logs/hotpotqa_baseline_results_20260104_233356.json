{
  "experiment_name": "hotpotqa_baseline",
  "start_time": "2026-01-04T23:33:45.954574",
  "config": {
    "name": "hotpotqa_baseline",
    "description": "HotPotQA baseline evaluation without optimization",
    "dataset": {
      "name": "hotpotqa",
      "train_size": 100,
      "dev_size": 20,
      "test_size": 0,
      "params": {
        "use_context": true
      }
    },
    "model": {
      "name": "ollama_chat/qwen3:4b-instruct",
      "api_base": "http://localhost:11434",
      "cache": true,
      "params": {}
    },
    "optimizer": {
      "name": "baseline",
      "auto": "light",
      "num_threads": 1,
      "params": {}
    },
    "program": {
      "name": "mlflow_base_prompt",
      "params": {}
    }
  },
  "baseline_results": {
    "total_score": 11.147728283984005,
    "avg_score": 0.5573864141992002,
    "dataset_size": 20,
    "individual_scores": [
      1.0,
      0.2727272727272727,
      1.0,
      0.4444444444444445,
      0.2608695652173913,
      1.0,
      0,
      1.0,
      0.5454545454545454,
      1.0,
      1.0,
      0.03125,
      0,
      0,
      0.6666666666666666,
      1.0,
      0.4,
      0.5263157894736842,
      0,
      1.0
    ]
  },
  "optimization_results": {},
  "final_results": {},
  "timeline": [
    {
      "timestamp": "2026-01-04T23:33:45.954699",
      "event": "config_loaded",
      "data": {
        "name": "hotpotqa_baseline",
        "description": "HotPotQA baseline evaluation without optimization",
        "dataset": {
          "name": "hotpotqa",
          "train_size": 100,
          "dev_size": 20,
          "test_size": 0,
          "params": {
            "use_context": true
          }
        },
        "model": {
          "name": "ollama_chat/qwen3:4b-instruct",
          "api_base": "http://localhost:11434",
          "cache": true,
          "params": {}
        },
        "optimizer": {
          "name": "baseline",
          "auto": "light",
          "num_threads": 1,
          "params": {}
        },
        "program": {
          "name": "mlflow_base_prompt",
          "params": {}
        }
      }
    },
    {
      "timestamp": "2026-01-04T23:33:45.954822",
      "event": "model_setup",
      "data": {
        "model": "ollama_chat/qwen3:4b-instruct",
        "cache": true
      }
    },
    {
      "timestamp": "2026-01-04T23:33:56.105466",
      "event": "dataset_loaded",
      "data": {
        "dataset": "hotpotqa",
        "train_size": 100,
        "val_size": 20,
        "test_size": 0
      }
    },
    {
      "timestamp": "2026-01-04T23:33:56.127435",
      "event": "baseline_evaluated",
      "data": {
        "total_score": 11.147728283984005,
        "avg_score": 0.5573864141992002,
        "dataset_size": 20,
        "individual_scores": [
          1.0,
          0.2727272727272727,
          1.0,
          0.4444444444444445,
          0.2608695652173913,
          1.0,
          0,
          1.0,
          0.5454545454545454,
          1.0,
          1.0,
          0.03125,
          0,
          0,
          0.6666666666666666,
          1.0,
          0.4,
          0.5263157894736842,
          0,
          1.0
        ]
      }
    }
  ],
  "end_time": "2026-01-04T23:33:56.127438"
}